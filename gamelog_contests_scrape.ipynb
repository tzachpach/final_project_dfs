{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 2514614,
     "sourceType": "datasetVersion",
     "datasetId": 1523149
    }
   ],
   "dockerImageVersionId": 30120,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1>NBA Data Generator</h1>\n",
    "<p>\n",
    "This notebook generates data relating to the NBA using the nba_api library (https://github.com/swar/nba_api)\n",
    "\n",
    "</p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Configuration</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from fuzzywuzzy import process\n",
    "import warnings\n",
    "from nba_api.stats.endpoints import leaguegamefinder, boxscoretraditionalv2, boxscoreadvancedv2, playergamelogs\n",
    "from nba_api.stats.library.parameters import Season, SeasonType\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "# import unidecode, os, sys, unicodedata\n",
    "from urllib.request import urlopen\n",
    "from urllib import request\n",
    "from tqdm import tqdm\n",
    "from datetime import date, datetime\n",
    "from dateutil import rrule\n",
    "import ssl\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "get_new_games, get_new_pbp, get_new_rosters, get_new_shotcharts = False, False, False, False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Player Gamelogs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "### Retrieves game-by-game stats for all players in a specified season\n",
    "\n",
    "latest_season = 24\n",
    "number_of_seasons = 10\n",
    "\n",
    "box_score_types = ['Base', 'Advanced', 'Scoring', 'Usage'] #'Four Factors', 'Misc', 'Opponent' not applicable\n",
    "\n",
    "def gamelog_scrape(box_score_type):\n",
    "\n",
    "# if get_new_player_gamelogs:\n",
    "#     # Iterate through the seasons and save each season to a csv\n",
    "    for n in range(0, number_of_seasons):\n",
    "        # construct the season name with multiple-year convention\n",
    "        season_name = f\"20{latest_season-(n+1)}-{latest_season-n}\"\n",
    "        # request the gamelogs for the season\n",
    "        playergamefinder = playergamelogs.PlayerGameLogs(season_nullable=season_name, measure_type_player_game_logs_nullable=box_score_type, league_id_nullable='00')\n",
    "        gamelog_df = playergamefinder.get_data_frames()\n",
    "        # save the returned results to csv\n",
    "        gamelog_df[0].to_csv(f\"data/gamelogs_2015-24/player_gamelogs_{box_score_type}_{season_name}.csv\")\n",
    "        # print(f\"Player gamelogs obtained for 20{latest_season-n}\")\n",
    "\n",
    "for type in box_score_types:\n",
    "    gamelog_scrape(type)\n"
   ],
   "metadata": {},
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge Gamelogs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all columns for 4 gamelog types merged, after cleaning: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "['SEASON_YEAR',\n 'PLAYER_ID',\n 'PLAYER_NAME',\n 'TEAM_ID',\n 'TEAM_ABBREVIATION',\n 'GAME_ID',\n 'GAME_DATE',\n 'WL',\n 'MIN',\n 'FGM',\n 'FGA',\n 'FG_PCT',\n 'FG3M',\n 'FG3A',\n 'FG3_PCT',\n 'FTM',\n 'FTA',\n 'FT_PCT',\n 'OREB',\n 'DREB',\n 'REB',\n 'AST',\n 'TOV',\n 'STL',\n 'BLK',\n 'BLKA',\n 'PF',\n 'PFD',\n 'PTS',\n 'PLUS_MINUS',\n 'NBA_FANTASY_PTS',\n 'DD2',\n 'TD3',\n 'WNBA_FANTASY_PTS',\n 'AVAILABLE_FLAG',\n 'E_OFF_RATING',\n 'OFF_RATING',\n 'sp_work_OFF_RATING',\n 'E_DEF_RATING',\n 'DEF_RATING',\n 'sp_work_DEF_RATING',\n 'E_NET_RATING',\n 'NET_RATING',\n 'sp_work_NET_RATING',\n 'AST_PCT',\n 'AST_TO',\n 'AST_RATIO',\n 'OREB_PCT',\n 'DREB_PCT',\n 'REB_PCT',\n 'TM_TOV_PCT',\n 'E_TOV_PCT',\n 'EFG_PCT',\n 'TS_PCT',\n 'USG_PCT_x',\n 'E_USG_PCT',\n 'E_PACE',\n 'PACE',\n 'PACE_PER40',\n 'sp_work_PACE',\n 'PIE',\n 'POSS',\n 'FGM_PG',\n 'FGA_PG',\n 'PCT_FGA_2PT',\n 'PCT_FGA_3PT',\n 'PCT_PTS_2PT',\n 'PCT_PTS_2PT_MR',\n 'PCT_PTS_3PT',\n 'PCT_PTS_FB',\n 'PCT_PTS_FT',\n 'PCT_PTS_OFF_TOV',\n 'PCT_PTS_PAINT',\n 'PCT_AST_2PM',\n 'PCT_UAST_2PM',\n 'PCT_AST_3PM',\n 'PCT_UAST_3PM',\n 'PCT_AST_FGM',\n 'PCT_UAST_FGM',\n 'PCT_FGM',\n 'PCT_FGA',\n 'PCT_FG3M',\n 'PCT_FG3A',\n 'PCT_FTM',\n 'PCT_FTA',\n 'PCT_OREB',\n 'PCT_DREB',\n 'PCT_REB',\n 'PCT_AST',\n 'PCT_TOV',\n 'PCT_STL',\n 'PCT_BLK',\n 'PCT_BLKA',\n 'PCT_PF',\n 'PCT_PFD',\n 'PCT_PTS']"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the directories containing the CSV files for basic and advanced game logs\n",
    "season_names = []\n",
    "for n in range(0, number_of_seasons):\n",
    "    # construct the season name with multiple-year convention\n",
    "    season_name = f\"20{latest_season-(n+1)}-{latest_season-n}\"\n",
    "    season_names.append(season_name)\n",
    "\n",
    "base_dir = 'data/gamelogs_2015-24/base'\n",
    "adv_dir = 'data/gamelogs_2015-24/advanced'\n",
    "scoring_dir = 'data/gamelogs_2015-24/scoring'\n",
    "usage_dir = 'data/gamelogs_2015-24/usage'\n",
    "output_dir = 'data/gamelogs_2015-24'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through each season\n",
    "for season in season_names:\n",
    "    base_file = os.path.join(base_dir, f'player_gamelogs_Base_{season}.csv')\n",
    "    adv_file = os.path.join(adv_dir, f'player_gamelogs_Advanced_{season}.csv')\n",
    "    scoring_file = os.path.join(scoring_dir, f'player_gamelogs_Scoring_{season}.csv')\n",
    "    usage_file = os.path.join(usage_dir, f'player_gamelogs_Usage_{season}.csv')\n",
    "\n",
    "    # Load the CSV files as dataframes\n",
    "    df1, df2, df3, df4 = pd.read_csv(base_file), pd.read_csv(adv_file), pd.read_csv(scoring_file), pd.read_csv(usage_file)\n",
    "    unique_cols_2 = [col for col in df2.columns if col not in df1.columns or col in ['PLAYER_ID', 'GAME_ID']]\n",
    "    unique_cols_3 = [col for col in df3.columns if col not in df1.columns or col in ['PLAYER_ID', 'GAME_ID']]\n",
    "    unique_cols_4 = [col for col in df4.columns if col not in df1.columns or col in ['PLAYER_ID', 'GAME_ID']]\n",
    "\n",
    "    # Sequentially merge the 4 dataframes on 'PLAYER_ID' and 'GAME_ID'\n",
    "    merged_df = pd.merge(df1, df2[unique_cols_2], on=['PLAYER_ID', 'GAME_ID'], how='outer')\n",
    "    merged_df = pd.merge(merged_df, df3[unique_cols_3], on=['PLAYER_ID', 'GAME_ID'], how='outer')\n",
    "    merged_df = pd.merge(merged_df, df4[unique_cols_4], on=['PLAYER_ID', 'GAME_ID'], how='outer')\n",
    "\n",
    "    # Data cleaning:\n",
    "    # index, nickname, team name full, matchup, RANK columns, USG_PCT dupe\n",
    "\n",
    "    merged_df.drop(merged_df.columns[[0, 4, 7, 10, 155]], axis=1, inplace=True)\n",
    "    merged_df.drop(merged_df.loc[:, 'GP_RANK':'WNBA_FANTASY_PTS_RANK'], axis=1, inplace=True)\n",
    "    merged_df.drop(merged_df.loc[:, 'E_OFF_RATING_RANK':'FGA_PG_RANK'], axis=1, inplace=True)\n",
    "    merged_df.drop(merged_df.loc[:, 'PCT_FGA_2PT_RANK':'PCT_UAST_FGM_RANK'], axis=1, inplace=True)\n",
    "    merged_df.drop(merged_df.loc[:, 'USG_PCT_RANK_y':'PCT_PTS_RANK'], axis=1, inplace=True)\n",
    "\n",
    "    # Write the merged dataframe to a new CSV file\n",
    "    output_file = os.path.join(output_dir, f'player_gamelogs_merged_{season}.csv')\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'all columns for 4 gamelog types merged, after cleaning: \\n')\n",
    "display(merged_df.columns)\n",
    "    # print(f'Merged CSV for season {season} has been created.')\n",
    "\n",
    "# print(\"All seasons have been processed.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gamelogs_dir = 'data/gamelogs_2015-24'\n",
    "salaries_dir = 'data/salaries_data'\n",
    "\n",
    "gamelog_df = pd.read_csv('/gamelogs_2015-24)'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'season_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mseason_names\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'season_names' is not defined"
     ]
    }
   ],
   "source": [
    "season_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DFS Contest Scraper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [01:52<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Contest Scrape Filters\n",
    "min_buyin = 1\n",
    "max_buyin = 1000\n",
    "min_entrants = 500\n",
    "min_prizepool = 10000\n",
    "\n",
    "nba_season = '2021-22'\n",
    "start_date = datetime.strptime('2021-10-19', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2022-04-10', '%Y-%m-%d')\n",
    "today = date.today()\n",
    "\n",
    "dates = []\n",
    "for dt in rrule.rrule(rrule.DAILY, dtstart=start_date, until=end_date):\n",
    "    dates.append(dt.date().strftime('%Y-%m-%d'))\n",
    "\n",
    "dfs_contests_df = pd.DataFrame()\n",
    "\n",
    "for x in tqdm(dates):\n",
    "    url = (\"https://www.fantasycruncher.com/funcs/tournament-analyzer/get-contests.php\")\n",
    "\n",
    "    data = {\n",
    "        \"sites[]\": [\"fanduel\",\"draftkings\", \"yahoo\"],\n",
    "        \"leagues[]\": \"NBA\",\n",
    "        \"periods[]\": x,}\n",
    "    # print(x)\n",
    "    try:\n",
    "        data = requests.post(url, data=data).json()\n",
    "\n",
    "        df = pd.json_normalize(data)\n",
    "        df = df[df.Title == 'Main']\n",
    "        df = df[df.cost >= min_buyin]\n",
    "        df = df[df.cost <= max_buyin]\n",
    "        df = df[df.max_entrants >= min_entrants]\n",
    "        df = df[df.prizepool >= min_prizepool]\n",
    "        df = df.sort_values('prizepool', ascending=False)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df = df.iloc[0,:]\n",
    "        dfs_contests_df = pd.concat([dfs_contests_df, df], axis=1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "dfs_contests_df = dfs_contests_df.T\n",
    "# print(dfs_contests_df)\n",
    "dfs_contests_df.to_csv(f'dfs_contests_{nba_season}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Other data pulls"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Games"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2788 games loaded for season 2019\n",
      "2785 games loaded for season 2018\n",
      "2829 games loaded for season 2017\n",
      "2856 games loaded for season 2016\n",
      "2864 games loaded for season 2015\n",
      "COMPLETE: Games Loaded\n"
     ]
    }
   ],
   "source": [
    "#### Get the game data\n",
    "### This needs to be run for the current season at the conclusion of every set of games\n",
    "if get_new_games:\n",
    "    # Initialise empty array to hold the new games\n",
    "    games = []\n",
    "    # Iterate through the seasons and save each season to a csv\n",
    "    for n in range(0, number_of_seasons):\n",
    "        season_name = f\"20{latest_season-(n+1)}-{latest_season-n}\"\n",
    "        gamefinder = leaguegamefinder.LeagueGameFinder(season_nullable=season_name, league_id_nullable='00')\n",
    "        game_df = gamefinder.get_data_frames()\n",
    "        games.append(game_df[0])\n",
    "        game_df[0].to_csv(f\"games_20{latest_season-n}.csv\")\n",
    "        print(f\"{len(game_df[0])} games loaded for 20{latest_season-n} season\")\n",
    "    # print(\"COMPLETE: Games Loaded\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Play-by-Play"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Get the play by play data\n",
    "###  Pulls a play by play account of individual games\n",
    "### This needs to be run when new games are pulled through in above\n",
    "#### YAFO NOTE 5.Jul.2024 - not touching play-by-play data yet\n",
    "\n",
    "# from nba_api.stats.endpoints import playbyplay\n",
    "#\n",
    "# all_pbp = pd.DataFrame()\n",
    "#\n",
    "# if get_new_pbp:\n",
    "#     # Iterate through the seasons and save each season to a csv\n",
    "#     for n in range(0, number_of_seasons):\n",
    "#         # Load the csv containing the games\n",
    "#         games_file = Path(f\"Data/Games/games_20{latest_season-n}.csv\")\n",
    "#         if games_file.is_file():\n",
    "#             games_df = pd.read_csv(games_file, index_col=None, header=0, low_memory=False)\n",
    "#             # get the list of unique game ids for season\n",
    "#             unique_game_ids = games_df['GAME_ID'].unique()\n",
    "#             # initiate an empty array and dataframe\n",
    "#             play_by_play = []\n",
    "#             existing_pbp = pd.DataFrame()\n",
    "#             # Check if a file already exists for the season(s) being searched for\n",
    "#             season_file = Path(f\"Data/PBP/play_by_play_20{latest_season-n}.csv\")\n",
    "#             if season_file.is_file():\n",
    "#                 existing_pbp = pd.read_csv(season_file, index_col=None, header=0, low_memory=False)\n",
    "#                 # Do a set difference to get a list of game ids that do not already exist\n",
    "#                 unique_game_ids = np.setdiff1d(unique_game_ids, existing_pbp['GAME_ID'].unique())\n",
    "#             # Check if there are any new games\n",
    "#             if len(unique_game_ids) > 0:\n",
    "#                 # Iterate through each unique game id to get the play by play data\n",
    "#                 for g_id in unique_game_ids:\n",
    "#                     # throttles requests to prevent api from blocking them\n",
    "#                     time.sleep(.600)\n",
    "#                     # make the request (the request expects a string which is padded with 2 00's)\n",
    "#                     game_id_padded = f\"00{g_id}\"\n",
    "#                     game_df = playbyplay.PlayByPlay(game_id_padded, timeout=1000).get_data_frames()[0]\n",
    "#                     play_by_play.append(game_df)\n",
    "#                 # Concatenate all the returned entries\n",
    "#                 all_pbp = pd.concat(play_by_play, axis=0, ignore_index=True)\n",
    "#                 # If there is an existing file, concatenate with those entries\n",
    "#                 if season_file.is_file():\n",
    "#                     all_pbp = pd.concat([all_pbp, existing_pbp], axis=0, ignore_index=True)\n",
    "#                 all_pbp = all_pbp.drop(\"Unnamed: 0\", axis=1)\n",
    "#                 all_pbp.to_csv(f\"Data/PBP/play_by_play_20{latest_season-n}.csv\")\n",
    "#                 print(f\"{len(unique_game_ids)} games loaded for 20{latest_season-n}\")\n",
    "#                 print(f\"{len(all_pbp)} plays in total for 20{latest_season-n}\")\n",
    "#             else:\n",
    "#                 print(f\"All play by plays loaded for games in 20{latest_season-n}\")\n",
    "#         else:\n",
    "#             print(f\"ERROR: No games found for season 20{latest_season-n}\")\n",
    "#     print(\"COMPLETE: Play by play loaded\")\n",
    "# else:\n",
    "#     print(\"Play by Play not requested (as per configuration)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rosters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Get the rosters\n",
    "### Retrieves the player rosters for teams\n",
    "### Does not need to be run often\n",
    "#\n",
    "# from nba_api.stats.static import teams\n",
    "# from nba_api.stats.endpoints import commonteamroster\n",
    "#\n",
    "# if get_new_rosters:\n",
    "#     # Get the team ids\n",
    "#     nba_teams = teams.get_teams()\n",
    "#     nba_team_ids = [team['id'] for team in nba_teams]\n",
    "#     # Iterate through the required seasons and teams to get the rosters, save each season to a csv\n",
    "#     for n in range(0, number_of_seasons):\n",
    "#         season_name = f\"20{latest_season-(n+1)}-{latest_season-n}\"\n",
    "#         rosters = []\n",
    "#         for team in nba_team_ids:\n",
    "#             # throttles requests to prevent api from blocking them\n",
    "#             time.sleep(.600)\n",
    "#             roster = commonteamroster.CommonTeamRoster(team_id=team, season=season_name, timeout=1000).get_data_frames()[0]\n",
    "#             rosters.append(roster)\n",
    "#         # concatenate all the returned entries and save to csv\n",
    "#         season_rosters = pd.concat(rosters, axis=0, ignore_index=True)\n",
    "#         season_rosters.to_csv(f\"Data/Rosters/rosters_20{latest_season-n}.csv\")\n",
    "#         print(f\"All rosters loaded for 20{latest_season-n}\")\n",
    "#     print(\"COMPLETE: Rosters loaded\")\n",
    "# else:\n",
    "#     print(\"Rosters not requested (as per configuration)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shot Charts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Get the shot charts\n",
    "### Retrieves shot chart based on team and player (mandatory inputs)\n",
    "# from nba_api.stats.endpoints import shotchartdetail\n",
    "#\n",
    "# if get_new_shotcharts:\n",
    "#     for n in range(0, number_of_seasons):\n",
    "#         # Load the csv containing the rosters\n",
    "#         rosters_file = Path(f\"Data/Rosters/rosters_20{latest_season-n}.csv\")\n",
    "#         if rosters_file.is_file():\n",
    "#             rosters_df = pd.read_csv(rosters_file, index_col=None, header=0, low_memory=False)\n",
    "#             shotcharts = []\n",
    "#             # Iterate through the players and teams to get shot charts\n",
    "#             # *may end up with duplicate shot charts where a player is at the same team more than one season\n",
    "#             for row in rosters_df.itertuples():\n",
    "#                 player_id = row.PLAYER_ID\n",
    "#                 team_id = row.TeamID\n",
    "#                 # throttles requests to prevent api from blocking them\n",
    "#                 time.sleep(.600)\n",
    "#                 # requests shotchartdetail for player and team team with context field goals attempted (FGA)\n",
    "#                 sc_df = shotchartdetail.ShotChartDetail(player_id=player_id, team_id=team_id, context_measure_simple='FGA').get_data_frames()[0]\n",
    "#                 shotcharts.append(sc_df)\n",
    "#             # concatenate the results together and save to csv\n",
    "#             season_shotchart = pd.concat(shotcharts, axis=0, ignore_index=True)\n",
    "#             season_shotchart.to_csv(f\"Data/ShotCharts/shotchart_20{latest_season-n}.csv\")\n",
    "#             print(f\"Shotcharts obtained for 20{latest_season-n}\")\n",
    "#         else:\n",
    "#             print(f\"ERROR: No roster file found for 20{latest_season-n}\")\n",
    "#     print(\"COMPLETE: Shotcharts obtained\")\n",
    "# else:\n",
    "#     print(\"Shotcharts not requested (as per configuration)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
