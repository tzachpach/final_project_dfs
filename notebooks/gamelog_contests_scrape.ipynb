{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 2514614,
     "sourceType": "datasetVersion",
     "datasetId": 1523149
    }
   ],
   "dockerImageVersionId": 30120,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1>NBA Data Generator</h1>\n",
    "<p>\n",
    "This notebook generates data relating to the NBA using the nba_api library (https://github.com/swar/nba_api)\n",
    "\n",
    "</p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Configuration</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from fuzzywuzzy import process\n",
    "import warnings\n",
    "from nba_api.stats.endpoints import leaguegamefinder, boxscoretraditionalv2, boxscoreadvancedv2, playergamelogs\n",
    "from nba_api.stats.library.parameters import Season, SeasonType\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "# import unidecode, os, sys, unicodedata\n",
    "from urllib.request import urlopen\n",
    "from urllib import request\n",
    "import urllib3\n",
    "import certifi\n",
    "from tqdm import tqdm\n",
    "from datetime import date, datetime\n",
    "from dateutil import rrule\n",
    "import ssl\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "get_new_games, get_new_pbp, get_new_rosters, get_new_shotcharts = False, False, False, False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Player Gamelogs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "### Retrieves game-by-game stats for all players in a specified season\n",
    "\n",
    "latest_season = 24\n",
    "number_of_seasons = 10\n",
    "\n",
    "box_score_types = ['Base', 'Advanced', 'Scoring', 'Usage'] #'Four Factors', 'Misc', 'Opponent' not applicable\n",
    "\n",
    "def gamelog_scrape(box_score_type):\n",
    "\n",
    "# if get_new_player_gamelogs:\n",
    "#     # Iterate through the seasons and save each season to a csv\n",
    "    for n in range(0, number_of_seasons):\n",
    "        # construct the season name with multiple-year convention\n",
    "        season_name = f\"20{latest_season-(n+1)}-{latest_season-n}\"\n",
    "        # request the gamelogs for the season\n",
    "        playergamefinder = playergamelogs.PlayerGameLogs(season_nullable=season_name, measure_type_player_game_logs_nullable=box_score_type, league_id_nullable='00')\n",
    "        gamelog_df = playergamefinder.get_data_frames()\n",
    "        # save the returned results to csv\n",
    "        gamelog_df[0].to_csv(f\"data/gamelogs_2015-24/player_gamelogs_{box_score_type}_{season_name}.csv\")\n",
    "        # print(f\"Player gamelogs obtained for 20{latest_season-n}\")\n",
    "\n",
    "for type in box_score_types:\n",
    "    gamelog_scrape(type)\n"
   ],
   "metadata": {},
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge Gamelogs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all columns for 4 gamelog types merged, after cleaning: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "['SEASON_YEAR',\n 'PLAYER_ID',\n 'PLAYER_NAME',\n 'TEAM_ID',\n 'TEAM_ABBREVIATION',\n 'GAME_ID',\n 'GAME_DATE',\n 'WL',\n 'MIN',\n 'FGM',\n 'FGA',\n 'FG_PCT',\n 'FG3M',\n 'FG3A',\n 'FG3_PCT',\n 'FTM',\n 'FTA',\n 'FT_PCT',\n 'OREB',\n 'DREB',\n 'REB',\n 'AST',\n 'TOV',\n 'STL',\n 'BLK',\n 'BLKA',\n 'PF',\n 'PFD',\n 'PTS',\n 'PLUS_MINUS',\n 'NBA_FANTASY_PTS',\n 'DD2',\n 'TD3',\n 'WNBA_FANTASY_PTS',\n 'AVAILABLE_FLAG',\n 'E_OFF_RATING',\n 'OFF_RATING',\n 'sp_work_OFF_RATING',\n 'E_DEF_RATING',\n 'DEF_RATING',\n 'sp_work_DEF_RATING',\n 'E_NET_RATING',\n 'NET_RATING',\n 'sp_work_NET_RATING',\n 'AST_PCT',\n 'AST_TO',\n 'AST_RATIO',\n 'OREB_PCT',\n 'DREB_PCT',\n 'REB_PCT',\n 'TM_TOV_PCT',\n 'E_TOV_PCT',\n 'EFG_PCT',\n 'TS_PCT',\n 'USG_PCT_x',\n 'E_USG_PCT',\n 'E_PACE',\n 'PACE',\n 'PACE_PER40',\n 'sp_work_PACE',\n 'PIE',\n 'POSS',\n 'FGM_PG',\n 'FGA_PG',\n 'PCT_FGA_2PT',\n 'PCT_FGA_3PT',\n 'PCT_PTS_2PT',\n 'PCT_PTS_2PT_MR',\n 'PCT_PTS_3PT',\n 'PCT_PTS_FB',\n 'PCT_PTS_FT',\n 'PCT_PTS_OFF_TOV',\n 'PCT_PTS_PAINT',\n 'PCT_AST_2PM',\n 'PCT_UAST_2PM',\n 'PCT_AST_3PM',\n 'PCT_UAST_3PM',\n 'PCT_AST_FGM',\n 'PCT_UAST_FGM',\n 'PCT_FGM',\n 'PCT_FGA',\n 'PCT_FG3M',\n 'PCT_FG3A',\n 'PCT_FTM',\n 'PCT_FTA',\n 'PCT_OREB',\n 'PCT_DREB',\n 'PCT_REB',\n 'PCT_AST',\n 'PCT_TOV',\n 'PCT_STL',\n 'PCT_BLK',\n 'PCT_BLKA',\n 'PCT_PF',\n 'PCT_PFD',\n 'PCT_PTS']"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the directories containing the CSV files for basic and advanced game logs\n",
    "season_names = []\n",
    "for n in range(0, number_of_seasons):\n",
    "    # construct the season name with multiple-year convention\n",
    "    season_name = f\"20{latest_season-(n+1)}-{latest_season-n}\"\n",
    "    season_names.append(season_name)\n",
    "\n",
    "base_dir = 'data/gamelogs_2015-24/base'\n",
    "adv_dir = 'data/gamelogs_2015-24/advanced'\n",
    "scoring_dir = 'data/gamelogs_2015-24/scoring'\n",
    "usage_dir = 'data/gamelogs_2015-24/usage'\n",
    "output_dir = 'data/gamelogs_2015-24'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through each season\n",
    "for season in season_names:\n",
    "    base_file = os.path.join(base_dir, f'player_gamelogs_Base_{season}.csv')\n",
    "    adv_file = os.path.join(adv_dir, f'player_gamelogs_Advanced_{season}.csv')\n",
    "    scoring_file = os.path.join(scoring_dir, f'player_gamelogs_Scoring_{season}.csv')\n",
    "    usage_file = os.path.join(usage_dir, f'player_gamelogs_Usage_{season}.csv')\n",
    "\n",
    "    # Load the CSV files as dataframes\n",
    "    df1, df2, df3, df4 = pd.read_csv(base_file), pd.read_csv(adv_file), pd.read_csv(scoring_file), pd.read_csv(usage_file)\n",
    "    unique_cols_2 = [col for col in df2.columns if col not in df1.columns or col in ['PLAYER_ID', 'GAME_ID']]\n",
    "    unique_cols_3 = [col for col in df3.columns if col not in df1.columns or col in ['PLAYER_ID', 'GAME_ID']]\n",
    "    unique_cols_4 = [col for col in df4.columns if col not in df1.columns or col in ['PLAYER_ID', 'GAME_ID']]\n",
    "\n",
    "    # Sequentially merge the 4 dataframes on 'PLAYER_ID' and 'GAME_ID'\n",
    "    merged_df = pd.merge(df1, df2[unique_cols_2], on=['PLAYER_ID', 'GAME_ID'], how='outer')\n",
    "    merged_df = pd.merge(merged_df, df3[unique_cols_3], on=['PLAYER_ID', 'GAME_ID'], how='outer')\n",
    "    merged_df = pd.merge(merged_df, df4[unique_cols_4], on=['PLAYER_ID', 'GAME_ID'], how='outer')\n",
    "\n",
    "    # Data cleaning:\n",
    "    # index, nickname, team name full, matchup, RANK columns, USG_PCT dupe\n",
    "\n",
    "    merged_df.drop(merged_df.columns[[0, 4, 7, 10, 155]], axis=1, inplace=True)\n",
    "    merged_df.drop(merged_df.loc[:, 'GP_RANK':'WNBA_FANTASY_PTS_RANK'], axis=1, inplace=True)\n",
    "    merged_df.drop(merged_df.loc[:, 'E_OFF_RATING_RANK':'FGA_PG_RANK'], axis=1, inplace=True)\n",
    "    merged_df.drop(merged_df.loc[:, 'PCT_FGA_2PT_RANK':'PCT_UAST_FGM_RANK'], axis=1, inplace=True)\n",
    "    merged_df.drop(merged_df.loc[:, 'USG_PCT_RANK_y':'PCT_PTS_RANK'], axis=1, inplace=True)\n",
    "\n",
    "    # Write the merged dataframe to a new CSV file\n",
    "    output_file = os.path.join(output_dir, f'player_gamelogs_merged_{season}.csv')\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'all columns for 4 gamelog types merged, after cleaning: \\n')\n",
    "display(merged_df.columns)\n",
    "    # print(f'Merged CSV for season {season} has been created.')\n",
    "\n",
    "# print(\"All seasons have been processed.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gamelogs & Salaries Data Merge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "gamelogs_dir = 'data/gamelogs_2015-24/'\n",
    "salaries_dir = 'data/salaries_data/'\n",
    "output_dir = 'data/gamelogs_salaries_2016-24/'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of seasons to process\n",
    "seasons = ['2016-17', '2017-18', '2018-19', '2019-20', '2020-21', '2021-22', '2022-23', '2023-24']\n",
    "\n",
    "# Iterate through each season\n",
    "for season in seasons:\n",
    "    gamelogs_file = os.path.join(gamelogs_dir, f'player_gamelogs_merged_{season}.csv')\n",
    "    salaries_file = os.path.join(salaries_dir, f'NBA-{season}-DFS-Dataset.csv')\n",
    "\n",
    "    # Load the CSV files\n",
    "    if os.path.exists(gamelogs_file) and os.path.exists(salaries_file):\n",
    "        gamelogs_df = pd.read_csv(gamelogs_file)\n",
    "        salaries_df = pd.read_csv(salaries_file, header=1)\n",
    "        salaries_df.rename(columns={'PLAYER ID': 'PLAYER_ID', 'GAME ID': 'GAME_ID'}, inplace=True)\n",
    "\n",
    "        unique_cols_salaries = [col for col in salaries_df.columns if col not in gamelogs_df.columns or col in ['PLAYER_ID', 'GAME_ID']]\n",
    "        # Merge the dataframes on 'PLAYER_ID' and 'GAME_ID'\n",
    "        merged_df = pd.merge(gamelogs_df, salaries_df[unique_cols_salaries], on=['PLAYER_ID', 'GAME_ID'], how='outer')\n",
    "\n",
    "        # Write the merged dataframe to a new CSV file\n",
    "        output_file = os.path.join(output_dir, f'gamelogs_salaries_{season}.csv')\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "        # print(f'Merged CSV for season {season} has been created.')\n",
    "    else:\n",
    "        print(f'Files for season {season} not found. Skipping...')\n",
    "\n",
    "# print(\"All seasons have been processed.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DFS Contest Scraper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [03:50<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Contest Scrape Filters\n",
    "# THIS REVISED CODE WORKS FOR FANDUEL a/o JAN 25 2025\n",
    "min_buyin = 1\n",
    "max_buyin = 10000\n",
    "min_entrants = 50\n",
    "min_prizepool = 1000\n",
    "\n",
    "# nba_season = '2021-22'\n",
    "# start_date = datetime.strptime('2021-10-19', '%Y-%m-%d')\n",
    "# end_date = datetime.strptime('2022-04-10', '%Y-%m-%d')\n",
    "nba_season = '2022-23'\n",
    "# start_date = datetime.strptime('2022-10-18', '%Y-%m-%d')\n",
    "# end_date = datetime.strptime('2023-04-09', '%Y-%m-%d')\n",
    "start_date = datetime.strptime('2022-10-18', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2023-04-09', '%Y-%m-%d')\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "dates = []\n",
    "for dt in rrule.rrule(rrule.DAILY, dtstart=start_date, until=end_date):\n",
    "    dates.append(dt.date().strftime('%Y-%m-%d'))\n",
    "\n",
    "dfs_contests_df = pd.DataFrame()\n",
    "\n",
    "for x in tqdm(dates):\n",
    "    url = \"https://www.fantasycruncher.com/funcs/tournament-analyzer/get-contests.php\"\n",
    "\n",
    "    data = {\n",
    "        \"sites[]\": [\"draftkings\", \"fanduel\", \"yahoo\"],\n",
    "        \"leagues[]\": \"NBA\",\n",
    "        \"periods[]\": x,\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Explicitly force TLS 1.2\n",
    "    context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n",
    "    context.verify_mode = ssl.CERT_REQUIRED\n",
    "    context.load_verify_locations(certifi.where())\n",
    "\n",
    "    session = requests.Session()\n",
    "    adapter = requests.adapters.HTTPAdapter()\n",
    "    adapter.poolmanager.ssl_context = context\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    try:\n",
    "        response = session.post(url, data=data, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        #print(response.json())  # Debug output\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "\n",
    "    try:\n",
    "        data_json = response.json()\n",
    "        df = pd.json_normalize(data_json)\n",
    "        df = df[df.Title == 'Main']\n",
    "        df = df[df.cost >= min_buyin]\n",
    "        df = df[df.cost <= max_buyin]\n",
    "        df = df[df.max_entrants >= min_entrants]\n",
    "        df = df[df.prizepool >= min_prizepool]\n",
    "        df = df.sort_values('prizepool', ascending=False)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df = df.iloc[0,:]\n",
    "        dfs_contests_df = pd.concat([dfs_contests_df, df], axis=1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # try:\n",
    "    #     data = requests.post(url, data=data).json()\n",
    "    #\n",
    "    #     df = pd.json_normalize(data)\n",
    "    #     df = df[df.Title == 'Main']\n",
    "    #     df = df[df.cost >= min_buyin]\n",
    "    #     df = df[df.cost <= max_buyin]\n",
    "    #     df = df[df.max_entrants >= min_entrants]\n",
    "    #     df = df[df.prizepool >= min_prizepool]\n",
    "    #     df = df.sort_values('prizepool', ascending=False)\n",
    "    # except:\n",
    "    #     pass\n",
    "    # try:\n",
    "    #     df = df.iloc[0,:]\n",
    "    #     dfs_contests_df = pd.concat([dfs_contests_df, df], axis=1)\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "dfs_contests_df = dfs_contests_df.T\n",
    "# print(dfs_contests_df)\n",
    "dfs_contests_df.to_csv(f'data/contests_data/dfs_contests_fanduel_{nba_season}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                 site league  slate          site_id  \\\n",
      "0    1201956724              fanduel    NBA  87809  87809-263176164   \n",
      "1    1201956705              fanduel    NBA  87809  87809-263176196   \n",
      "2    1201950975           draftkings    NBA  83536        142249907   \n",
      "3    1201835151           draftkings    NBA  83536        142237346   \n",
      "4    1201956718              fanduel    NBA  87809  87809-263176167   \n",
      "..          ...                  ...    ...    ...              ...   \n",
      "538  1202373994              fanduel    NBA  87809  87809-263187757   \n",
      "539  1202374427       fanduel_single    NBA  87817  87817-263184447   \n",
      "540  1202374428       fanduel_single    NBA  87817  87817-263184446   \n",
      "541  1202451788  draftkings_showdown    NBA  83541        142277593   \n",
      "542  1202508825  draftkings_showdown    NBA  83541        142284566   \n",
      "\n",
      "                                                  name      period  \\\n",
      "0        $7K Fri NBA Piggy Bank Shot (150 Entries Max)  2023-03-10   \n",
      "1                     $200K Fri NBA Shot ($40K to 1st)  2023-03-10   \n",
      "2                      NBA $35K And-One [20 Entry Max]  2023-03-10   \n",
      "3              NBA $7.5K Quarter Jukebox [Just $0.25!]  2023-03-10   \n",
      "4    $7K Fri NBA Fadeaway (Only $0.25 to Enter, 20 ...  2023-03-10   \n",
      "..                                                 ...         ...   \n",
      "538                             3-Player League ($109)  2023-03-10   \n",
      "539                            3-Player Contest ($109)  2023-03-10   \n",
      "540                            3-Player Contest ($109)  2023-03-10   \n",
      "541            NBA Showdown $162 3-Player (TOR vs LAL)  2023-03-10   \n",
      "542            NBA Showdown $162 3-Player (TOR vs LAL)  2023-03-10   \n",
      "\n",
      "     max_entries  max_entrants    cost  ...  mincash_score   startdate  \\\n",
      "0            150        167664    0.05  ...         292.50  1678492800   \n",
      "1            150         42900    5.55  ...         297.10  1678492800   \n",
      "2             20         41617    1.00  ...         278.00  1678492800   \n",
      "3             20         35671    0.25  ...         282.50  1678492800   \n",
      "4             20         33533    0.25  ...         289.80  1678492800   \n",
      "..           ...           ...     ...  ...            ...         ...   \n",
      "538            1             3  109.00  ...         269.90  1678492800   \n",
      "539            1             3  109.00  ...         237.46  1678505400   \n",
      "540            1             3  109.00  ...         237.46  1678505400   \n",
      "541            1             3  162.00  ...         233.38  1678505400   \n",
      "542            1             3  162.00  ...         233.38  1678505400   \n",
      "\n",
      "     winning_payout  mincash_payout             DateTime         Title  \\\n",
      "0             350.0             0.1  2023-03-10 19:00:00          Main   \n",
      "1           40000.0            10.0  2023-03-10 19:00:00          Main   \n",
      "2            1500.0             1.5  2023-03-10 19:00:00     Late Swap   \n",
      "3             300.0             0.5  2023-03-10 19:00:00     Late Swap   \n",
      "4             350.0             0.5  2023-03-10 19:00:00          Main   \n",
      "..              ...             ...                  ...           ...   \n",
      "538           300.0           300.0  2023-03-10 19:00:00          Main   \n",
      "539           300.0           300.0  2023-03-10 22:30:00     TOR @ LAL   \n",
      "540           300.0           300.0  2023-03-10 22:30:00     TOR @ LAL   \n",
      "541           450.0           450.0  2023-03-10 22:30:00  (TOR vs LAL)   \n",
      "542           450.0           450.0  2023-03-10 22:30:00  (TOR vs LAL)   \n",
      "\n",
      "     game_cnt  winner_cnt           winner has_lineups  \n",
      "0           6           0    reallife_rick           1  \n",
      "1           6           0         booourns           1  \n",
      "2           6           1  SeanOReilly1988           1  \n",
      "3           6           1  SeanOReilly1988           1  \n",
      "4           6           0      wheeler3058           1  \n",
      "..        ...         ...              ...         ...  \n",
      "538         6           0             None           0  \n",
      "539         1           0             None           0  \n",
      "540         1           0             None           0  \n",
      "541         1           1         moklovin           1  \n",
      "542         1           1         moklovin           1  \n",
      "\n",
      "[543 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import ssl\n",
    "import certifi\n",
    "\n",
    "url = \"https://www.fantasycruncher.com/funcs/tournament-analyzer/get-contests.php\"\n",
    "\n",
    "data = {\n",
    "    \"sites[]\": [\"draftkings\", \"fanduel\", \"yahoo\"],\n",
    "    \"leagues[]\": \"NBA\",\n",
    "    \"periods[]\": \"2023-03-10\",\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Explicitly force TLS 1.2\n",
    "context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n",
    "context.verify_mode = ssl.CERT_REQUIRED\n",
    "context.load_verify_locations(certifi.where())\n",
    "\n",
    "session = requests.Session()\n",
    "adapter = requests.adapters.HTTPAdapter()\n",
    "adapter.poolmanager.ssl_context = context\n",
    "session.mount(\"https://\", adapter)\n",
    "\n",
    "try:\n",
    "    response = session.post(url, data=data, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    #print(response.json())  # Debug output\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n",
    "\n",
    "data_json = response.json()\n",
    "df = pd.json_normalize(data_json)\n",
    "print(df)\n",
    "df.to_csv('dfs_contests_fanduel_2023-03-10.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='www.fantasycruncher.com', port=443): Max retries exceeded with url: /funcs/tournament-analyzer/get-contests.php (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)')))",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mSSLEOFError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/urllib3/connectionpool.py:714\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 714\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    715\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    716\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    717\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    718\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    719\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    720\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    721\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    722\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    724\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    725\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    726\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/urllib3/connectionpool.py:403\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    402\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 403\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    405\u001B[0m     \u001B[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001B[39;00m\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/urllib3/connectionpool.py:1053\u001B[0m, in \u001B[0;36mHTTPSConnectionPool._validate_conn\u001B[0;34m(self, conn)\u001B[0m\n\u001B[1;32m   1052\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(conn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msock\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):  \u001B[38;5;66;03m# AppEngine might not have  `.sock`\u001B[39;00m\n\u001B[0;32m-> 1053\u001B[0m     \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1055\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m conn\u001B[38;5;241m.\u001B[39mis_verified:\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/urllib3/connection.py:419\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    417\u001B[0m     context\u001B[38;5;241m.\u001B[39mload_default_certs()\n\u001B[0;32m--> 419\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[43mssl_wrap_socket\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    420\u001B[0m \u001B[43m    \u001B[49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeyfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    422\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcertfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcert_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey_password\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_password\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    424\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_certs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_certs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_cert_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_cert_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_cert_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_cert_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m    \u001B[49m\u001B[43mssl_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtls_in_tls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtls_in_tls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;66;03m# If we're using all defaults and the connection\u001B[39;00m\n\u001B[1;32m    433\u001B[0m \u001B[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001B[39;00m\n\u001B[1;32m    434\u001B[0m \u001B[38;5;66;03m# for the host.\u001B[39;00m\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/urllib3/util/ssl_.py:449\u001B[0m, in \u001B[0;36mssl_wrap_socket\u001B[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m send_sni:\n\u001B[0;32m--> 449\u001B[0m     ssl_sock \u001B[38;5;241m=\u001B[39m \u001B[43m_ssl_wrap_socket_impl\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[43m        \u001B[49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtls_in_tls\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\n\u001B[1;32m    451\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/urllib3/util/ssl_.py:493\u001B[0m, in \u001B[0;36m_ssl_wrap_socket_impl\u001B[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001B[0m\n\u001B[1;32m    492\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m server_hostname:\n\u001B[0;32m--> 493\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mssl_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrap_socket\u001B[49m\u001B[43m(\u001B[49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/ssl.py:513\u001B[0m, in \u001B[0;36mSSLContext.wrap_socket\u001B[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001B[0m\n\u001B[1;32m    507\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrap_socket\u001B[39m(\u001B[38;5;28mself\u001B[39m, sock, server_side\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    508\u001B[0m                 do_handshake_on_connect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    509\u001B[0m                 suppress_ragged_eofs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    510\u001B[0m                 server_hostname\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, session\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    511\u001B[0m     \u001B[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001B[39;00m\n\u001B[1;32m    512\u001B[0m     \u001B[38;5;66;03m# ctx._wrap_socket()\u001B[39;00m\n\u001B[0;32m--> 513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msslsocket_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    514\u001B[0m \u001B[43m        \u001B[49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    515\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_side\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_side\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_handshake_on_connect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_handshake_on_connect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43msuppress_ragged_eofs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msuppress_ragged_eofs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msession\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/ssl.py:1071\u001B[0m, in \u001B[0;36mSSLSocket._create\u001B[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001B[0m\n\u001B[1;32m   1070\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1071\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_handshake\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1072\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mOSError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/ssl.py:1342\u001B[0m, in \u001B[0;36mSSLSocket.do_handshake\u001B[0;34m(self, block)\u001B[0m\n\u001B[1;32m   1341\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msettimeout(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m-> 1342\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_handshake\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1343\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[0;31mSSLEOFError\u001B[0m: [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/requests/adapters.py:486\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    485\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 486\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/urllib3/connectionpool.py:798\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    796\u001B[0m     e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n\u001B[0;32m--> 798\u001B[0m retries \u001B[38;5;241m=\u001B[39m \u001B[43mretries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    801\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/urllib3/util/retry.py:592\u001B[0m, in \u001B[0;36mRetry.increment\u001B[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_retry\u001B[38;5;241m.\u001B[39mis_exhausted():\n\u001B[0;32m--> 592\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause))\n\u001B[1;32m    594\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n",
      "\u001B[0;31mMaxRetryError\u001B[0m: HTTPSConnectionPool(host='www.fantasycruncher.com', port=443): Max retries exceeded with url: /funcs/tournament-analyzer/get-contests.php (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mSSLError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 28>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     25\u001B[0m urllib3\u001B[38;5;241m.\u001B[39mdisable_warnings()\n\u001B[1;32m     27\u001B[0m s \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mSession()\n\u001B[0;32m---> 28\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43ms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverify\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcertifi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mtext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/requests/sessions.py:637\u001B[0m, in \u001B[0;36mSession.post\u001B[0;34m(self, url, data, json, **kwargs)\u001B[0m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\u001B[38;5;28mself\u001B[39m, url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001B[39;00m\n\u001B[1;32m    628\u001B[0m \n\u001B[1;32m    629\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    634\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 637\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPOST\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m/Users/yafo/miniconda3/envs/nlp/lib/python3.10/site-packages/requests/adapters.py:517\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    513\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ProxyError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    515\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, _SSLError):\n\u001B[1;32m    516\u001B[0m         \u001B[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001B[39;00m\n\u001B[0;32m--> 517\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m SSLError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    519\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    521\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ClosedPoolError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mSSLError\u001B[0m: HTTPSConnectionPool(host='www.fantasycruncher.com', port=443): Max retries exceeded with url: /funcs/tournament-analyzer/get-contests.php (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)')))"
     ]
    }
   ],
   "source": [
    "import certifi\n",
    "\n",
    "url = \"https://www.fantasycruncher.com/funcs/tournament-analyzer/get-contests.php\"\n",
    "\n",
    "data = {\n",
    "    \"sites[]\": [\n",
    "        \"draftkings\",\n",
    "        \"draftkings_pickem\",\n",
    "        \"draftkings_showdown\",\n",
    "        \"fanduel\",\n",
    "        \"fanduel_single\",\n",
    "        \"fanduel_super\",\n",
    "        \"fantasydraft\",\n",
    "        \"yahoo\",\n",
    "        \"superdraft\",\n",
    "    ],\n",
    "    \"leagues[]\": \"NBA\",\n",
    "    \"periods[]\": \"2023-03-10\",\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "s = requests.Session()\n",
    "response = s.post(url, data=data, headers=headers, verify=certifi.where())\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n",
    "else:\n",
    "    data_json = response.json()\n",
    "    df = pd.json_normalize(data_json)\n",
    "    print(df)\n",
    "    df.to_csv('dfs_contests_fanduel_2023-03-10.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Contest Scrape Filters\n",
    "min_buyin = 1\n",
    "max_buyin = 100000\n",
    "min_entrants = 100\n",
    "min_prizepool = 10000\n",
    "\n",
    "nba_season = '2022-23'\n",
    "start_date = datetime.strptime('2022-10-18', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2023-04-09', '%Y-%m-%d')\n",
    "\n",
    "dates = []\n",
    "for dt in rrule.rrule(rrule.DAILY, dtstart=start_date, until=end_date):\n",
    "    dates.append(dt.date().strftime('%Y-%m-%d'))\n",
    "\n",
    "dfs_contests_df = {site: pd.DataFrame() for site in [\"fanduel\", \"draftkings\", \"yahoo\"]}\n",
    "\n",
    "def fetch_data(url, data):\n",
    "    max_retries = 3\n",
    "    for _ in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(url, data=data)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching data: {e}\")\n",
    "            time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "    return None\n",
    "\n",
    "for x in tqdm(dates):\n",
    "    url = \"https://www.fantasycruncher.com/funcs/tournament-analyzer/get-contests.php\"\n",
    "\n",
    "    for site in [\"fanduel\", \"draftkings\", \"yahoo\"]:\n",
    "        data = {\n",
    "            \"sites[]\": [site],\n",
    "            \"leagues[]\": \"NBA\",\n",
    "            \"periods[]\": x,\n",
    "        }\n",
    "\n",
    "        json_data = fetch_data(url, data)\n",
    "\n",
    "        if json_data:\n",
    "            df = pd.json_normalize(json_data)\n",
    "            if not df.empty:\n",
    "                df = df[df.Title == 'Main']\n",
    "                df = df[\n",
    "                    (df.cost >= min_buyin) &\n",
    "                    (df.cost <= max_buyin) &\n",
    "                    (df.max_entrants >= min_entrants) &\n",
    "                    (df.prizepool >= min_prizepool)\n",
    "                ]\n",
    "                df = df.sort_values('prizepool', ascending=False)\n",
    "\n",
    "                if not df.empty:\n",
    "                    dfs_contests_df[site] = pd.concat([dfs_contests_df[site], df], ignore_index=True)\n",
    "\n",
    "        time.sleep(1)  # Add a 1-second delay between requests\n",
    "\n",
    "# Process and save data for each site\n",
    "for site, df in dfs_contests_df.items():\n",
    "    if not df.empty:\n",
    "        df['date'] = pd.to_datetime(df['DateTime']).dt.date\n",
    "        df = df.sort_values(['date', 'site'])\n",
    "        df.to_csv(f'dfs_contests_{nba_season}_{site}.csv', index=False)\n",
    "        print(f\"Scraped {len(df)} contests for {site}.\")\n",
    "    else:\n",
    "        print(f\"No data scraped for {site}.\")\n",
    "\n",
    "print(\"Scraping completed.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Contests Season Dates:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nba_season = '2016-17'\n",
    "start_date = datetime.strptime('2016-10-25', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2017-04-12', '%Y-%m-%d')\n",
    "\n",
    "nba_season = '2017-18'\n",
    "start_date = datetime.strptime('2017-10-17', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2018-04-11', '%Y-%m-%d')\n",
    "\n",
    "nba_season = '2018-19'\n",
    "start_date = datetime.strptime('2018-10-16', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2019-04-10', '%Y-%m-%d')\n",
    "\n",
    "nba_season = '2019-20'\n",
    "start_date = datetime.strptime('2019-10-22', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2020-08-14', '%Y-%m-%d')\n",
    "\n",
    "nba_season = '2020-21'\n",
    "start_date = datetime.strptime('2020-12-22', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2021-05-16', '%Y-%m-%d')\n",
    "\n",
    "nba_season = '2021-22'\n",
    "start_date = datetime.strptime('2021-10-19', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2022-04-10', '%Y-%m-%d')\n",
    "\n",
    "nba_season = '2022-23'\n",
    "start_date = datetime.strptime('2022-10-18', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2023-04-09', '%Y-%m-%d')\n",
    "\n",
    "nba_season = '2023-24'\n",
    "start_date = datetime.strptime('2023-10-24', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2024-04-14', '%Y-%m-%d')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Other data pulls"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Games"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2788 games loaded for season 2019\n",
      "2785 games loaded for season 2018\n",
      "2829 games loaded for season 2017\n",
      "2856 games loaded for season 2016\n",
      "2864 games loaded for season 2015\n",
      "COMPLETE: Games Loaded\n"
     ]
    }
   ],
   "source": [
    "#### Get the game data\n",
    "### This needs to be run for the current season at the conclusion of every set of games\n",
    "if get_new_games:\n",
    "    # Initialise empty array to hold the new games\n",
    "    games = []\n",
    "    # Iterate through the seasons and save each season to a csv\n",
    "    for n in range(0, number_of_seasons):\n",
    "        season_name = f\"20{latest_season-(n+1)}-{latest_season-n}\"\n",
    "        gamefinder = leaguegamefinder.LeagueGameFinder(season_nullable=season_name, league_id_nullable='00')\n",
    "        game_df = gamefinder.get_data_frames()\n",
    "        games.append(game_df[0])\n",
    "        game_df[0].to_csv(f\"games_20{latest_season-n}.csv\")\n",
    "        print(f\"{len(game_df[0])} games loaded for 20{latest_season-n} season\")\n",
    "    # print(\"COMPLETE: Games Loaded\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Play-by-Play"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Get the play by play data\n",
    "###  Pulls a play by play account of individual games\n",
    "### This needs to be run when new games are pulled through in above\n",
    "#### YAFO NOTE 5.Jul.2024 - not touching play-by-play data yet\n",
    "\n",
    "# from nba_api.stats.endpoints import playbyplay\n",
    "#\n",
    "# all_pbp = pd.DataFrame()\n",
    "#\n",
    "# if get_new_pbp:\n",
    "#     # Iterate through the seasons and save each season to a csv\n",
    "#     for n in range(0, number_of_seasons):\n",
    "#         # Load the csv containing the games\n",
    "#         games_file = Path(f\"Data/Games/games_20{latest_season-n}.csv\")\n",
    "#         if games_file.is_file():\n",
    "#             games_df = pd.read_csv(games_file, index_col=None, header=0, low_memory=False)\n",
    "#             # get the list of unique game ids for season\n",
    "#             unique_game_ids = games_df['GAME_ID'].unique()\n",
    "#             # initiate an empty array and dataframe\n",
    "#             play_by_play = []\n",
    "#             existing_pbp = pd.DataFrame()\n",
    "#             # Check if a file already exists for the season(s) being searched for\n",
    "#             season_file = Path(f\"Data/PBP/play_by_play_20{latest_season-n}.csv\")\n",
    "#             if season_file.is_file():\n",
    "#                 existing_pbp = pd.read_csv(season_file, index_col=None, header=0, low_memory=False)\n",
    "#                 # Do a set difference to get a list of game ids that do not already exist\n",
    "#                 unique_game_ids = np.setdiff1d(unique_game_ids, existing_pbp['GAME_ID'].unique())\n",
    "#             # Check if there are any new games\n",
    "#             if len(unique_game_ids) > 0:\n",
    "#                 # Iterate through each unique game id to get the play by play data\n",
    "#                 for g_id in unique_game_ids:\n",
    "#                     # throttles requests to prevent api from blocking them\n",
    "#                     time.sleep(.600)\n",
    "#                     # make the request (the request expects a string which is padded with 2 00's)\n",
    "#                     game_id_padded = f\"00{g_id}\"\n",
    "#                     game_df = playbyplay.PlayByPlay(game_id_padded, timeout=1000).get_data_frames()[0]\n",
    "#                     play_by_play.append(game_df)\n",
    "#                 # Concatenate all the returned entries\n",
    "#                 all_pbp = pd.concat(play_by_play, axis=0, ignore_index=True)\n",
    "#                 # If there is an existing file, concatenate with those entries\n",
    "#                 if season_file.is_file():\n",
    "#                     all_pbp = pd.concat([all_pbp, existing_pbp], axis=0, ignore_index=True)\n",
    "#                 all_pbp = all_pbp.drop(\"Unnamed: 0\", axis=1)\n",
    "#                 all_pbp.to_csv(f\"Data/PBP/play_by_play_20{latest_season-n}.csv\")\n",
    "#                 print(f\"{len(unique_game_ids)} games loaded for 20{latest_season-n}\")\n",
    "#                 print(f\"{len(all_pbp)} plays in total for 20{latest_season-n}\")\n",
    "#             else:\n",
    "#                 print(f\"All play by plays loaded for games in 20{latest_season-n}\")\n",
    "#         else:\n",
    "#             print(f\"ERROR: No games found for season 20{latest_season-n}\")\n",
    "#     print(\"COMPLETE: Play by play loaded\")\n",
    "# else:\n",
    "#     print(\"Play by Play not requested (as per configuration)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rosters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Get the rosters\n",
    "### Retrieves the player rosters for teams\n",
    "### Does not need to be run often\n",
    "#\n",
    "# from nba_api.stats.static import teams\n",
    "# from nba_api.stats.endpoints import commonteamroster\n",
    "#\n",
    "# if get_new_rosters:\n",
    "#     # Get the team ids\n",
    "#     nba_teams = teams.get_teams()\n",
    "#     nba_team_ids = [team['id'] for team in nba_teams]\n",
    "#     # Iterate through the required seasons and teams to get the rosters, save each season to a csv\n",
    "#     for n in range(0, number_of_seasons):\n",
    "#         season_name = f\"20{latest_season-(n+1)}-{latest_season-n}\"\n",
    "#         rosters = []\n",
    "#         for team in nba_team_ids:\n",
    "#             # throttles requests to prevent api from blocking them\n",
    "#             time.sleep(.600)\n",
    "#             roster = commonteamroster.CommonTeamRoster(team_id=team, season=season_name, timeout=1000).get_data_frames()[0]\n",
    "#             rosters.append(roster)\n",
    "#         # concatenate all the returned entries and save to csv\n",
    "#         season_rosters = pd.concat(rosters, axis=0, ignore_index=True)\n",
    "#         season_rosters.to_csv(f\"Data/Rosters/rosters_20{latest_season-n}.csv\")\n",
    "#         print(f\"All rosters loaded for 20{latest_season-n}\")\n",
    "#     print(\"COMPLETE: Rosters loaded\")\n",
    "# else:\n",
    "#     print(\"Rosters not requested (as per configuration)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shot Charts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Get the shot charts\n",
    "### Retrieves shot chart based on team and player (mandatory inputs)\n",
    "# from nba_api.stats.endpoints import shotchartdetail\n",
    "#\n",
    "# if get_new_shotcharts:\n",
    "#     for n in range(0, number_of_seasons):\n",
    "#         # Load the csv containing the rosters\n",
    "#         rosters_file = Path(f\"Data/Rosters/rosters_20{latest_season-n}.csv\")\n",
    "#         if rosters_file.is_file():\n",
    "#             rosters_df = pd.read_csv(rosters_file, index_col=None, header=0, low_memory=False)\n",
    "#             shotcharts = []\n",
    "#             # Iterate through the players and teams to get shot charts\n",
    "#             # *may end up with duplicate shot charts where a player is at the same team more than one season\n",
    "#             for row in rosters_df.itertuples():\n",
    "#                 player_id = row.PLAYER_ID\n",
    "#                 team_id = row.TeamID\n",
    "#                 # throttles requests to prevent api from blocking them\n",
    "#                 time.sleep(.600)\n",
    "#                 # requests shotchartdetail for player and team team with context field goals attempted (FGA)\n",
    "#                 sc_df = shotchartdetail.ShotChartDetail(player_id=player_id, team_id=team_id, context_measure_simple='FGA').get_data_frames()[0]\n",
    "#                 shotcharts.append(sc_df)\n",
    "#             # concatenate the results together and save to csv\n",
    "#             season_shotchart = pd.concat(shotcharts, axis=0, ignore_index=True)\n",
    "#             season_shotchart.to_csv(f\"Data/ShotCharts/shotchart_20{latest_season-n}.csv\")\n",
    "#             print(f\"Shotcharts obtained for 20{latest_season-n}\")\n",
    "#         else:\n",
    "#             print(f\"ERROR: No roster file found for 20{latest_season-n}\")\n",
    "#     print(\"COMPLETE: Shotcharts obtained\")\n",
    "# else:\n",
    "#     print(\"Shotcharts not requested (as per configuration)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
